{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Update: changing the batch_size from 32 to 128 when warm up the model, adding Kappa loss from this kernel: https://www.kaggle.com/christofhenkel/weighted-kappa-loss-for-keras-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aptos2019-blindness-detection', 'resnet50']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score, fbeta_score, cohen_kappa_score\n",
    "from keras.utils import Sequence\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "WORKERS = 2\n",
    "CHANNEL = 3\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 300\n",
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7f6dd2be48>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\n",
    "df_test = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\n",
    "\n",
    "x = df_train['id_code']\n",
    "y = df_train['diagnosis']\n",
    "\n",
    "x, y = shuffle(x, y, random_state=8)\n",
    "y.hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_multi_label(target):\n",
    "    multi_label = np.zeros((len(target), NUM_CLASSES))\n",
    "    for i in range(len(target)):\n",
    "        j = target[i] + 1\n",
    "        multi_label[i][:j] = 1\n",
    "    return np.array(multi_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3112,)\n",
      "(3112, 5)\n",
      "(550,)\n",
      "(550, 5)\n"
     ]
    }
   ],
   "source": [
    "# y = to_categorical(y, num_classes=NUM_CLASSES)\n",
    "multi_y = to_multi_label(y)\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(x, multi_y, test_size=0.15,\n",
    "                                                      stratify=y, random_state=8)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(valid_x.shape)\n",
    "print(valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/aleju/imgaug\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "seq = iaa.Sequential([\n",
    "    sometimes(\n",
    "        iaa.OneOf([\n",
    "            iaa.Add((-10, 10), per_channel=0.5),\n",
    "            iaa.Multiply((0.9, 1.1), per_channel=0.5),\n",
    "            iaa.ContrastNormalization((0.9, 1.1), per_channel=0.5)\n",
    "        ])\n",
    "    ),\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Crop(percent=(0, 0.1)),\n",
    "    iaa.Flipud(0.5)\n",
    "],random_order=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Generator(Sequence):\n",
    "\n",
    "    def __init__(self, image_filenames, labels,\n",
    "                 batch_size, is_train=False,\n",
    "                 mix=False, augment=False):\n",
    "        self.image_filenames, self.labels = image_filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "        self.is_train = is_train\n",
    "        self.is_augment = augment\n",
    "        if(self.is_train):\n",
    "            self.on_epoch_end()\n",
    "        self.is_mix = mix\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_filenames) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        if(self.is_train):\n",
    "            return self.train_generate(batch_x, batch_y)\n",
    "        return self.valid_generate(batch_x, batch_y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if(self.is_train):\n",
    "            self.image_filenames, self.labels = shuffle(self.image_filenames, self.labels)\n",
    "    \n",
    "    def mix_up(self, x, y):\n",
    "        lam = np.random.beta(0.2, 0.4)\n",
    "        ori_index = np.arange(int(len(x)))\n",
    "        index_array = np.arange(int(len(x)))\n",
    "        np.random.shuffle(index_array)        \n",
    "        \n",
    "        mixed_x = lam * x[ori_index] + (1 - lam) * x[index_array]\n",
    "        mixed_y = lam * y[ori_index] + (1 - lam) * y[index_array]\n",
    "        \n",
    "        return mixed_x, mixed_y\n",
    "\n",
    "    def train_generate(self, batch_x, batch_y):\n",
    "        batch_images = []\n",
    "        for (sample, label) in zip(batch_x, batch_y):\n",
    "            img = cv2.imread('../input/aptos2019-blindness-detection/train_images/'+sample+'.png')\n",
    "            img = cv2.resize(img, (SIZE, SIZE))\n",
    "            img = np.fft.fft2(img)\n",
    "            img = np.log(np.abs(img))\n",
    "            if(self.is_augment):\n",
    "                img = seq.augment_image(img)\n",
    "            batch_images.append(img)\n",
    "        batch_images = np.array(batch_images, np.float32) / 255\n",
    "        batch_y = np.array(batch_y, np.float32)\n",
    "        if(self.is_mix):\n",
    "            batch_images, batch_y = self.mix_up(batch_images, batch_y)\n",
    "        return batch_images, batch_y\n",
    "\n",
    "    def valid_generate(self, batch_x, batch_y):\n",
    "        batch_images = []\n",
    "        for (sample, label) in zip(batch_x, batch_y):\n",
    "            img = cv2.imread('../input/aptos2019-blindness-detection/train_images/'+sample+'.png')\n",
    "            img = cv2.resize(img, (SIZE, SIZE))\n",
    "            img = np.fft.fft2(img)\n",
    "            img = np.log(np.abs(img))\n",
    "            batch_images.append(img)\n",
    "        batch_images = np.array(batch_images, np.float32) / 255\n",
    "        batch_y = np.array(batch_y, np.float32)\n",
    "        return batch_images, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n",
    "                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D)\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = \"sigmoid\"\n",
    "def create_model(input_shape, n_out):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = ResNet50(include_top=False,\n",
    "                   weights=None,\n",
    "                   input_tensor=input_tensor)\n",
    "    base_model.load_weights('../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    final_output = Dense(n_out, activation=function, name='final_output')(x)\n",
    "    model = Model(input_tensor, final_output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n",
    "                             EarlyStopping, ReduceLROnPlateau,CSVLogger)\n",
    "\n",
    "epochs = 10; batch_size = 40\n",
    "checkpoint = ModelCheckpoint('../working/Resnet50.h5', monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, \n",
    "                                   verbose=1, mode='auto', epsilon=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=9)\n",
    "\n",
    "csv_logger = CSVLogger(filename='../working/training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "# callbacks_list = [checkpoint, csv_logger, reduceLROnPlat, early]\n",
    "\n",
    "train_generator = My_Generator(train_x, train_y, 128, is_train=True)\n",
    "train_mixup = My_Generator(train_x, train_y, batch_size, is_train=True, mix=False, augment=True)\n",
    "valid_generator = My_Generator(valid_x, valid_y, batch_size, is_train=False)\n",
    "\n",
    "model = create_model(\n",
    "    input_shape=(SIZE,SIZE,3), \n",
    "    n_out=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "class QWKEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), batch_size=64, interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.batch_size = batch_size\n",
    "        self.valid_generator, self.y_val = validation_data\n",
    "        self.history = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict_generator(generator=self.valid_generator,\n",
    "                                                  steps=np.ceil(float(len(self.y_val)) / float(self.batch_size)),\n",
    "                                                  workers=1, use_multiprocessing=False,\n",
    "                                                  verbose=1) > 0.5\n",
    "            def flatten(y):\n",
    "                # return np.argmax(y, axis=1).reshape(-1)\n",
    "                return np.sum(y.astype(int), axis=1).reshape(-1) - 1\n",
    "            \n",
    "            score = cohen_kappa_score(flatten(self.y_val),\n",
    "                                      flatten(y_pred),\n",
    "                                      labels=[0,1,2,3,4],\n",
    "                                      weights='quadratic')\n",
    "            print(\"\\n epoch: %d - QWK_score: %.6f \\n\" % (epoch+1, score))\n",
    "            self.history.append(score)\n",
    "            if score >= max(self.history):\n",
    "                print('save checkpoint: ', score)\n",
    "                self.model.save('../working/Resnet50_bestqwk.h5')\n",
    "\n",
    "qwk = QWKEvaluation(validation_data=(valid_generator, valid_y),\n",
    "                    batch_size=batch_size, interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "25/25 [==============================] - 210s 8s/step - loss: 0.5396\n",
      "14/14 [==============================] - 110s 8s/step\n",
      "\n",
      " epoch: 1 - QWK_score: 0.000000 \n",
      "\n",
      "save checkpoint:  0.0\n",
      "Epoch 2/2\n",
      "25/25 [==============================] - 121s 5s/step - loss: 0.4439\n",
      "14/14 [==============================] - 110s 8s/step\n",
      "\n",
      " epoch: 2 - QWK_score: 0.000000 \n",
      "\n",
      "save checkpoint:  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7f6b1aadd8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# warm up model\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for i in range(-3,0):\n",
    "    model.layers[i].trainable = True\n",
    "\n",
    "model.compile(\n",
    "#     loss ='categorical_crossentropy',\n",
    "    loss = 'binary_crossentropy',\n",
    "    optimizer=Adam(1e-3))\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=np.ceil(float(len(train_y)) / float(128)),\n",
    "    epochs=2,\n",
    "    workers=WORKERS, use_multiprocessing=True,\n",
    "    verbose=1,\n",
    "    callbacks=[qwk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "78/78 [==============================] - 330s 4s/step - loss: 0.4181 - val_loss: 0.4459\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44586, saving model to ../working/Resnet50.h5\n",
      "14/14 [==============================] - 88s 6s/step\n",
      "\n",
      " epoch: 1 - QWK_score: 0.000000 \n",
      "\n",
      "save checkpoint:  0.0\n",
      "Epoch 2/10\n",
      "78/78 [==============================] - 267s 3s/step - loss: 0.4163 - val_loss: 0.4298\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.44586 to 0.42981, saving model to ../working/Resnet50.h5\n",
      "14/14 [==============================] - 86s 6s/step\n",
      "\n",
      " epoch: 2 - QWK_score: 0.000000 \n",
      "\n",
      "save checkpoint:  0.0\n",
      "Epoch 3/10\n",
      "78/78 [==============================] - 262s 3s/step - loss: 0.4145 - val_loss: 0.4165\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.42981 to 0.41646, saving model to ../working/Resnet50.h5\n",
      "14/14 [==============================] - 85s 6s/step\n",
      "\n",
      " epoch: 3 - QWK_score: 0.000000 \n",
      "\n",
      "save checkpoint:  0.0\n",
      "Epoch 4/10\n",
      "78/78 [==============================] - 260s 3s/step - loss: 0.4153 - val_loss: 0.4127\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.41646 to 0.41274, saving model to ../working/Resnet50.h5\n",
      "14/14 [==============================] - 84s 6s/step\n",
      "\n",
      " epoch: 4 - QWK_score: 0.000000 \n",
      "\n",
      "save checkpoint:  0.0\n",
      "Epoch 5/10\n",
      "78/78 [==============================] - 259s 3s/step - loss: 0.4140 - val_loss: 0.4919\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.41274\n",
      "14/14 [==============================] - 85s 6s/step\n",
      "\n",
      " epoch: 5 - QWK_score: 0.000000 \n",
      "\n",
      "save checkpoint:  0.0\n",
      "Epoch 6/10\n",
      "78/78 [==============================] - 256s 3s/step - loss: 0.4137 - val_loss: 0.4275\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.41274\n",
      "14/14 [==============================] - 84s 6s/step\n",
      "\n",
      " epoch: 6 - QWK_score: 0.000000 \n",
      "\n",
      "save checkpoint:  0.0\n",
      "Epoch 7/10\n",
      "78/78 [==============================] - 256s 3s/step - loss: 0.4131 - val_loss: 0.4176\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.41274\n",
      "14/14 [==============================] - 83s 6s/step\n",
      "\n",
      " epoch: 7 - QWK_score: 0.000000 \n",
      "\n",
      "save checkpoint:  0.0\n",
      "Epoch 8/10\n",
      "78/78 [==============================] - 263s 3s/step - loss: 0.4128 - val_loss: 0.4085\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.41274 to 0.40854, saving model to ../working/Resnet50.h5\n",
      " 3/14 [=====>........................] - ETA: 1:25"
     ]
    }
   ],
   "source": [
    "# train all layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "callbacks_list = [checkpoint, csv_logger, reduceLROnPlat, qwk]\n",
    "model.compile(# loss='categorical_crossentropy',\n",
    "            # loss=kappa_loss,\n",
    "            loss='binary_crossentropy',\n",
    "            optimizer=Adam(lr=5e-5))\n",
    "\n",
    "model.fit_generator(\n",
    "    train_mixup,\n",
    "    steps_per_epoch=np.ceil(float(len(train_x)) / float(batch_size)),\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=np.ceil(float(len(valid_x)) / float(batch_size)),\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    workers=1, use_multiprocessing=False,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\n",
    "# model.load_weights('../working/Resnet50.h5')\n",
    "model.load_weights('../working/Resnet50_bestqwk.h5')\n",
    "predicted = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in tqdm(enumerate(submit['id_code'])):\n",
    "    path = os.path.join('../input/aptos2019-blindness-detection/test_images/', name+'.png')\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image, (SIZE, SIZE))\n",
    "    img = np.fft.fft2(img)\n",
    "    img = np.log(np.abs(img))\n",
    "    score_predict = model.predict((image[np.newaxis])/255) > 0.5\n",
    "    # label_predict = np.argmax(score_predict)\n",
    "    label_predict = score_predict.astype(int).sum() - 1\n",
    "    predicted.append(str(label_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['diagnosis'] = predicted\n",
    "submit.to_csv('submission.csv', index=False)\n",
    "submit.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
