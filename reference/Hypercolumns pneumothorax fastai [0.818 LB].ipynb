{"cells":[{"metadata":{},"cell_type":"markdown","source":"# unittest"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install torchsnooper","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting torchsnooper\n  Downloading https://files.pythonhosted.org/packages/df/bb/147923a1274155034189a3a622ac99781009a15928101b7f47afd1892cdb/TorchSnooper-0.5-py3-none-any.whl\nRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torchsnooper) (1.16.4)\nCollecting pysnooper>=0.1.0 (from torchsnooper)\n  Downloading https://files.pythonhosted.org/packages/c3/d3/af3c46f5936d165bbf1c6925da09806cc72f007951e5e0c9cf9a935f2b5f/PySnooper-0.2.2-py2.py3-none-any.whl\nInstalling collected packages: pysnooper, torchsnooper\nSuccessfully installed pysnooper-0.2.2 torchsnooper-0.5\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\n\n# Plot inline\n%matplotlib inline\n\n! ( wget http://23.105.212.181:8000/pytorchKernel.py -O pytorchKernel.py  && wget http://23.105.212.181:8000/utils.py -O utils.py && wget http://23.105.212.181:8000/hc_unet.py -O hc_unet.py &&  wget http://23.105.212.181:8000/unitTest.py -O unitTest.py ) > /dev/null 2>&1 \n\nimport unitTest\nimport importlib\nimport utils\n#import kernel\nimport pytorchKernel\n\nimportlib.reload(unitTest)\nimportlib.reload(utils)\n#importlib.reload(kernel)\nimportlib.reload(pytorchKernel)\n        \n#%run -m unittest unitTest.PSKenelTest.test_data_aug\n%run -m unittest unitTest.UnetTest.test_hc_unet","execution_count":null,"outputs":[{"output_type":"stream","text":"fold:  0\n","name":"stdout"},{"output_type":"stream","text":"Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /tmp/.cache/torch/checkpoints/resnext50_32x4d-7cdf4587.pth\n100%|██████████| 100441675/100441675 [00:06<00:00, 15259741.59it/s]\nStarting var:.. self = DynamicUnet_Hcolumns()\nStarting var:.. encoder = Sequential(  (0): Conv2d(3, 64, kernel_size=(7, ...g_stats=True)      (relu): ReLU(inplace)    )  ))\nStarting var:.. n_classes = 2\nStarting var:.. blur = False\nStarting var:.. blur_final = True\nStarting var:.. self_attention = True\nStarting var:.. y_range = None\nStarting var:.. last_cross = True\nStarting var:.. bottle = True\nStarting var:.. small = True\nStarting var:.. kwargs = {'norm_type': <enum 'NormType'>}\nStarting var:.. __class__ = <class 'hc_unet.DynamicUnet_Hcolumns'>\n15:28:58.961550 call       325     def __init__(self, encoder: nn.Module, n_classes: int, blur: bool = False, blur_final=True,\n15:28:58.963600 line       329         imsize = (256, 256)\nNew var:....... imsize = (256, 256)\n15:28:58.964570 line       333         sfs_szs = model_sizes(encoder, size=imsize)\nNew var:....... sfs_szs = [(1, 64, 128, 128), (1, 64, 128, 128), (1, 64, 1...56, 64, 64), (1, 512, 32, 32), (1, 1024, 16, 16)]\n15:28:59.346449 line       336         sfs_idxs = list(reversed(_get_sfs_idxs(sfs_szs)))\nNew var:....... sfs_idxs = [5, 4, 2]\n15:28:59.347827 line       338         self.sfs = hook_outputs([encoder[i] for i in sfs_idxs])\n15:28:59.349149 line       339         x = dummy_eval(encoder, imsize).detach()\nNew var:....... x = tensor<(1, 1024, 16, 16), float32, cpu>\n15:28:59.650720 line       341         ni = sfs_szs[-1][1]\nNew var:....... ni = 1024\n15:28:59.653509 line       342         if small:\n15:28:59.656301 line       343             middle_conv_size_down_scale = 2\nNew var:....... middle_conv_size_down_scale = 2\n15:28:59.658903 line       344             middle_conv = conv_layer(ni, ni//middle_conv_size_down_scale, **kwargs).eval()\nNew var:....... middle_conv = Sequential(  (0): Conv2d(1024, 512, kernel_size=...ride=(1, 1), padding=(1, 1))  (1): ReLU(inplace))\n15:28:59.755367 line       349         x = middle_conv(x)\nModified var:.. x = tensor<(1, 512, 16, 16), float32, cpu, grad>\n15:28:59.805723 line       350         layers = [encoder, batchnorm_2d(ni), nn.ReLU(), middle_conv]\nNew var:....... layers = [Sequential(  (0): Conv2d(3, 64, kernel_size=(7,...ide=(1, 1), padding=(1, 1))  (1): ReLU(inplace))]\n15:28:59.809984 line       352         if small:\n15:28:59.813076 line       353             self.hc_hooks = []\n15:28:59.816147 line       354             hc_c = []\nNew var:....... hc_c = []\n15:28:59.819580 line       359         for i, idx in enumerate(sfs_idxs):\nNew var:....... i = 0\nNew var:....... idx = 5\n15:28:59.822897 line       360             final_unet_flag = i == len(sfs_idxs) - 1\nNew var:....... final_unet_flag = False\n15:28:59.826210 line       361             up_in_c, x_in_c = int(x.shape[1]), int(sfs_szs[idx][1])\nNew var:....... up_in_c = 512\nNew var:....... x_in_c = 512\n15:28:59.829239 line       362             do_blur = blur and (final_unet_flag or blur_final)\nNew var:....... do_blur = False\n15:28:59.832222 line       363             sa = self_attention and (i == len(sfs_idxs) - 3)\nNew var:....... sa = True\n15:28:59.835584 line       364             unet_block_class = UnetBlockSmall if small else UnetBlock\nNew var:....... unet_block_class = <class 'hc_unet.UnetBlockSmall'>\n15:28:59.838680 line       365             unet_block = unet_block_class(up_in_c, x_in_c, self.sfs[i], final_div=final_unet_flag,\n15:28:59.841694 line       366                                    blur=blur, self_attention=sa, **kwargs).eval()\n    Starting var:.. self = UnetBlockSmall()\n    Starting var:.. up_in_c = 512\n    Starting var:.. x_in_c = 512\n    Starting var:.. hook = <fastai.callbacks.hooks.Hook object at 0x7fb40479ea58>\n    Starting var:.. final_div = False\n    Starting var:.. blur = False\n    Starting var:.. leaky = None\n    Starting var:.. self_attention = True\n    Starting var:.. kwargs = {'norm_type': <enum 'NormType'>}\n    15:28:59.842242 call       393     def __init__(self, up_in_c:int, x_in_c:int, hook:Hook, final_div:bool=True, blur:bool=False, leaky:float=None,\n    15:28:59.842443 line       395         self.hook = hook\n    15:28:59.842601 line       397         self.shuf = PixelShuffle_ICNR(up_in_c, up_in_c//2, blur=blur, leaky=leaky, **kwargs)\n    Modified var:.. self = UnetBlockSmall(  (shuf): PixelShuffle_ICNR(    (...stride=1, padding=0)    (relu): ReLU(inplace)  ))\n    15:28:59.860482 line       398         self.bn = batchnorm_2d(x_in_c)\n    Modified var:.. self = UnetBlockSmall(  (shuf): PixelShuffle_ICNR(    (...ntum=0.1, affine=True, track_running_stats=True))\n    15:28:59.861971 line       399         ni = up_in_c//2 + x_in_c\n    New var:....... ni = 768\n    15:28:59.862230 line       400         nf = ni if final_div else ni//4\n    New var:....... nf = 192\n    15:28:59.862463 line       401         self.conv1 = conv_layer(ni, nf, leaky=leaky, **kwargs)\n    Modified var:.. self = UnetBlockSmall(  (shuf): PixelShuffle_ICNR(    (...(1, 1), padding=(1, 1))    (1): ReLU(inplace)  ))\n    15:28:59.888176 line       402         self.conv2 = conv_layer(nf, nf, leaky=leaky, self_attention=self_attention, **kwargs)\n    Modified var:.. self = UnetBlockSmall(  (shuf): PixelShuffle_ICNR(    (...rnel_size=(1,), stride=(1,), bias=False)    )  ))\n    15:28:59.903092 line       403         self.relu = relu(leaky=leaky)\n    Modified var:.. self = UnetBlockSmall(  (shuf): PixelShuffle_ICNR(    (...stride=(1,), bias=False)    )  )  (relu): ReLU())\n    15:28:59.903532 return     403         self.relu = relu(leaky=leaky)\n    Return value:.. None\nNew var:....... unet_block = UnetBlockSmall(  (shuf): PixelShuffle_ICNR(    (...stride=(1,), bias=False)    )  )  (relu): ReLU())\n15:28:59.907775 line       367             print(unet_block)\n15:28:59.911743 line       368             layers.append(unet_block)\nModified var:.. layers = [Sequential(  (0): Conv2d(3, 64, kernel_size=(7,...tride=(1,), bias=False)    )  )  (relu): ReLU())]\n15:28:59.915248 line       369             x = unet_block(x)\nModified var:.. x = tensor<(1, 192, 32, 32), float32, cpu, grad>\n15:29:00.055655 line       371             self.hc_hooks.append(Hook(layers[-1], _hook_inner, detach=False))\n15:29:00.059420 line       372             hc_c.append(x.shape[1])\n","name":"stderr"},{"output_type":"stream","text":"UnetBlockSmall(\n  (shuf): PixelShuffle_ICNR(\n    (conv): Sequential(\n      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (shuf): PixelShuffle(upscale_factor=2)\n    (pad): ReplicationPad2d((1, 0, 1, 0))\n    (blur): AvgPool2d(kernel_size=2, stride=1, padding=0)\n    (relu): ReLU(inplace)\n  )\n  (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv1): Sequential(\n    (0): Conv2d(768, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace)\n  )\n  (conv2): Sequential(\n    (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace)\n    (2): SelfAttention(\n      (query): Conv1d(192, 24, kernel_size=(1,), stride=(1,), bias=False)\n      (key): Conv1d(192, 24, kernel_size=(1,), stride=(1,), bias=False)\n      (value): Conv1d(192, 192, kernel_size=(1,), stride=(1,), bias=False)\n    )\n  )\n  (relu): ReLU()\n)\n","name":"stdout"},{"output_type":"stream","text":"Modified var:.. hc_c = [192]\n15:29:00.063205 line       359         for i, idx in enumerate(sfs_idxs):\nModified var:.. i = 1\nModified var:.. idx = 4\n15:29:00.068731 line       360             final_unet_flag = i == len(sfs_idxs) - 1\n15:29:00.073308 line       361             up_in_c, x_in_c = int(x.shape[1]), int(sfs_szs[idx][1])\nModified var:.. up_in_c = 192\nModified var:.. x_in_c = 256\n15:29:00.077133 line       362             do_blur = blur and (final_unet_flag or blur_final)\n15:29:00.080788 line       363             sa = self_attention and (i == len(sfs_idxs) - 3)\nModified var:.. sa = False\n15:29:00.084579 line       364             unet_block_class = UnetBlockSmall if small else UnetBlock\n15:29:00.088533 line       365             unet_block = unet_block_class(up_in_c, x_in_c, self.sfs[i], final_div=final_unet_flag,\n15:29:00.092564 line       366                                    blur=blur, self_attention=sa, **kwargs).eval()\n    Starting var:.. self = UnetBlockSmall()\n    Starting var:.. up_in_c = 192\n    Starting var:.. x_in_c = 256\n    Starting var:.. hook = <fastai.callbacks.hooks.Hook object at 0x7fb40479e6a0>\n    Starting var:.. final_div = False\n    Starting var:.. blur = False\n    Starting var:.. leaky = None\n    Starting var:.. self_attention = False\n    Starting var:.. kwargs = {'norm_type': <enum 'NormType'>}\n    15:29:00.093116 call       393     def __init__(self, up_in_c:int, x_in_c:int, hook:Hook, final_div:bool=True, blur:bool=False, leaky:float=None,\n    15:29:00.093290 line       395         self.hook = hook\n    15:29:00.093474 line       397         self.shuf = PixelShuffle_ICNR(up_in_c, up_in_c//2, blur=blur, leaky=leaky, **kwargs)\n    Modified var:.. self = UnetBlockSmall(  (shuf): PixelShuffle_ICNR(    (...stride=1, padding=0)    (relu): ReLU(inplace)  ))\n    15:29:00.097514 line       398         self.bn = batchnorm_2d(x_in_c)\n    Modified var:.. self = UnetBlockSmall(  (shuf): PixelShuffle_ICNR(    (...ntum=0.1, affine=True, track_running_stats=True))\n    15:29:00.098703 line       399         ni = up_in_c//2 + x_in_c\n    New var:....... ni = 352\n    15:29:00.098961 line       400         nf = ni if final_div else ni//4\n    New var:....... nf = 88\n    15:29:00.099263 line       401         self.conv1 = conv_layer(ni, nf, leaky=leaky, **kwargs)\n    Modified var:.. self = UnetBlockSmall(  (shuf): PixelShuffle_ICNR(    (...(1, 1), padding=(1, 1))    (1): ReLU(inplace)  ))\n    15:29:00.105430 line       402         self.conv2 = conv_layer(nf, nf, leaky=leaky, self_attention=self_attention, **kwargs)\n    15:29:00.108026 line       403         self.relu = relu(leaky=leaky)\n    Modified var:.. self = UnetBlockSmall(  (shuf): PixelShuffle_ICNR(    (...(1, 1))    (1): ReLU(inplace)  )  (relu): ReLU())\n    15:29:00.108431 return     403         self.relu = relu(leaky=leaky)\n    Return value:.. None\nModified var:.. unet_block = UnetBlockSmall(  (shuf): PixelShuffle_ICNR(    (...(1, 1))    (1): ReLU(inplace)  )  (relu): ReLU())\n15:29:00.114022 line       367             print(unet_block)\n15:29:00.119428 line       368             layers.append(unet_block)\nModified var:.. layers = [Sequential(  (0): Conv2d(3, 64, kernel_size=(7,...1, 1))    (1): ReLU(inplace)  )  (relu): ReLU())]\n15:29:00.123085 line       369             x = unet_block(x)\nModified var:.. x = tensor<(1, 88, 64, 64), float32, cpu, grad>\n15:29:00.182501 line       371             self.hc_hooks.append(Hook(layers[-1], _hook_inner, detach=False))\n15:29:00.187709 line       372             hc_c.append(x.shape[1])\nModified var:.. hc_c = [192, 88]\n15:29:00.192407 line       359         for i, idx in enumerate(sfs_idxs):\nModified var:.. i = 2\nModified var:.. idx = 2\n15:29:00.197549 line       360             final_unet_flag = i == len(sfs_idxs) - 1\nModified var:.. final_unet_flag = True\n15:29:00.202300 line       361             up_in_c, x_in_c = int(x.shape[1]), int(sfs_szs[idx][1])\nModified var:.. up_in_c = 88\nModified var:.. x_in_c = 64\n15:29:00.207626 line       362             do_blur = blur and (final_unet_flag or blur_final)\n15:29:00.212798 line       363             sa = self_attention and (i == len(sfs_idxs) - 3)\n15:29:00.217675 line       364             unet_block_class = UnetBlockSmall if small else UnetBlock\n15:29:00.222458 line       365             unet_block = unet_block_class(up_in_c, x_in_c, self.sfs[i], final_div=final_unet_flag,\n15:29:00.227112 line       366                                    blur=blur, self_attention=sa, **kwargs).eval()\n    Starting var:.. self = UnetBlockSmall()\n    Starting var:.. up_in_c = 88\n    Starting var:.. x_in_c = 64\n    Starting var:.. hook = <fastai.callbacks.hooks.Hook object at 0x7fb40479e9e8>\n    Starting var:.. final_div = True\n    Starting var:.. blur = False\n    Starting var:.. leaky = None\n    Starting var:.. self_attention = False\n    Starting var:.. kwargs = {'norm_type': <enum 'NormType'>}\n    15:29:00.227708 call       393     def __init__(self, up_in_c:int, x_in_c:int, hook:Hook, final_div:bool=True, blur:bool=False, leaky:float=None,\n    15:29:00.228569 line       395         self.hook = hook\n    15:29:00.228883 line       397         self.shuf = PixelShuffle_ICNR(up_in_c, up_in_c//2, blur=blur, leaky=leaky, **kwargs)\n    Modified var:.. self = UnetBlockSmall(  (shuf): PixelShuffle_ICNR(    (...stride=1, padding=0)    (relu): ReLU(inplace)  ))\n    15:29:00.232371 line       398         self.bn = batchnorm_2d(x_in_c)\n    Modified var:.. self = UnetBlockSmall(  (shuf): PixelShuffle_ICNR(    (...ntum=0.1, affine=True, track_running_stats=True))\n    15:29:00.233420 line       399         ni = up_in_c//2 + x_in_c\n    New var:....... ni = 108\n    15:29:00.233733 line       400         nf = ni if final_div else ni//4\n    New var:....... nf = 108\n    15:29:00.234102 line       401         self.conv1 = conv_layer(ni, nf, leaky=leaky, **kwargs)\n    Modified var:.. self = UnetBlockSmall(  (shuf): PixelShuffle_ICNR(    (...(1, 1), padding=(1, 1))    (1): ReLU(inplace)  ))\n    15:29:00.237117 line       402         self.conv2 = conv_layer(nf, nf, leaky=leaky, self_attention=self_attention, **kwargs)\n    15:29:00.240094 line       403         self.relu = relu(leaky=leaky)\n    Modified var:.. self = UnetBlockSmall(  (shuf): PixelShuffle_ICNR(    (...(1, 1))    (1): ReLU(inplace)  )  (relu): ReLU())\n    15:29:00.240594 return     403         self.relu = relu(leaky=leaky)\n    Return value:.. None\n15:29:00.246184 line       367             print(unet_block)\n15:29:00.251476 line       368             layers.append(unet_block)\n15:29:00.256973 line       369             x = unet_block(x)\n","name":"stderr"},{"output_type":"stream","text":"UnetBlockSmall(\n  (shuf): PixelShuffle_ICNR(\n    (conv): Sequential(\n      (0): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (shuf): PixelShuffle(upscale_factor=2)\n    (pad): ReplicationPad2d((1, 0, 1, 0))\n    (blur): AvgPool2d(kernel_size=2, stride=1, padding=0)\n    (relu): ReLU(inplace)\n  )\n  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv1): Sequential(\n    (0): Conv2d(352, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace)\n  )\n  (conv2): Sequential(\n    (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace)\n  )\n  (relu): ReLU()\n)\nUnetBlockSmall(\n  (shuf): PixelShuffle_ICNR(\n    (conv): Sequential(\n      (0): Conv2d(88, 176, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (shuf): PixelShuffle(upscale_factor=2)\n    (pad): ReplicationPad2d((1, 0, 1, 0))\n    (blur): AvgPool2d(kernel_size=2, stride=1, padding=0)\n    (relu): ReLU(inplace)\n  )\n  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv1): Sequential(\n    (0): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace)\n  )\n  (conv2): Sequential(\n    (0): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace)\n  )\n  (relu): ReLU()\n)\n","name":"stdout"},{"output_type":"stream","text":"Modified var:.. x = tensor<(1, 108, 128, 128), float32, cpu, grad>\n15:29:00.408106 line       371             self.hc_hooks.append(Hook(layers[-1], _hook_inner, detach=False))\n15:29:00.420389 line       372             hc_c.append(x.shape[1])\nModified var:.. hc_c = [192, 88, 108]\n15:29:00.432530 line       359         for i, idx in enumerate(sfs_idxs):\n15:29:00.444955 line       374         ni = x.shape[1]\nModified var:.. ni = 108\n15:29:00.456477 line       375         if imsize != sfs_szs[0][-2:]: layers.append(PixelShuffle_ICNR(ni, **kwargs))\nModified var:.. layers = [Sequential(  (0): Conv2d(3, 64, kernel_size=(7,...=2, stride=1, padding=0)  (relu): ReLU(inplace))]\n15:29:00.470733 line       376         if last_cross:\n15:29:00.483227 line       377             layers.append(MergeLayer(dense=True))\nModified var:.. layers = [Sequential(  (0): Conv2d(3, 64, kernel_size=(7,...padding=0)  (relu): ReLU(inplace)), MergeLayer()]\n15:29:00.495541 line       378             ni += in_channels(encoder)\nModified var:.. ni = 111\n15:29:00.520861 line       379             layers.append(res_block(ni, bottle=bottle, **kwargs))\nModified var:.. layers = [Sequential(  (0): Conv2d(3, 64, kernel_size=(7,...(1): ReLU(inplace)    )    (2): MergeLayer()  ))]\n15:29:00.536789 line       381         hc_c.append(ni)\nModified var:.. hc_c = [192, 88, 108, 111]\n15:29:00.548799 line       382         layers.append(Hcolumns(self.hc_hooks, hc_c))\nModified var:.. layers = [Sequential(  (0): Conv2d(3, 64, kernel_size=(7,...111, kernel_size=(1, 1), stride=(1, 1))    )  ))]\n15:29:00.566741 line       383         layers += [conv_layer(ni * len(hc_c), n_classes, ks=1, use_activ=False, **kwargs)]\nModified var:.. layers = [Sequential(  (0): Conv2d(3, 64, kernel_size=(7,...nv2d(444, 2, kernel_size=(1, 1), stride=(1, 1)))]\n15:29:00.579711 line       384         if y_range is not None: layers.append(SigmoidRange(*y_range))\n15:29:00.591663 line       385         super().__init__(*layers)\nModified var:.. self = DynamicUnet_Hcolumns(  (layers): ModuleList(    ...4, 2, kernel_size=(1, 1), stride=(1, 1))    )  ))\n15:29:00.606084 return     385         super().__init__(*layers)\nReturn value:.. None\n","name":"stderr"},{"output_type":"stream","text":"DynamicUnet_Hcolumns(\n  (layers): ModuleList(\n    (0): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n      (2): ReLU(inplace)\n      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (4): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace)\n          (downsample): Sequential(\n            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(256, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace)\n        )\n      )\n      (5): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace)\n          (downsample): Sequential(\n            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): BatchNorm2d(512, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace)\n        )\n      )\n      (6): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace)\n          (downsample): Sequential(\n            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace)\n        )\n        (4): Bottleneck(\n          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace)\n        )\n        (5): Bottleneck(\n          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace)\n        )\n      )\n    )\n    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Sequential(\n      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace)\n    )\n    (4): UnetBlockSmall(\n      (shuf): PixelShuffle_ICNR(\n        (conv): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (shuf): PixelShuffle(upscale_factor=2)\n        (pad): ReplicationPad2d((1, 0, 1, 0))\n        (blur): AvgPool2d(kernel_size=2, stride=1, padding=0)\n        (relu): ReLU(inplace)\n      )\n      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n      (conv1): Sequential(\n        (0): Conv2d(768, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): ReLU(inplace)\n      )\n      (conv2): Sequential(\n        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): ReLU(inplace)\n        (2): SelfAttention(\n          (query): Conv1d(192, 24, kernel_size=(1,), stride=(1,), bias=False)\n          (key): Conv1d(192, 24, kernel_size=(1,), stride=(1,), bias=False)\n          (value): Conv1d(192, 192, kernel_size=(1,), stride=(1,), bias=False)\n        )\n      )\n      (relu): ReLU()\n    )\n    (5): UnetBlockSmall(\n      (shuf): PixelShuffle_ICNR(\n        (conv): Sequential(\n          (0): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (shuf): PixelShuffle(upscale_factor=2)\n        (pad): ReplicationPad2d((1, 0, 1, 0))\n        (blur): AvgPool2d(kernel_size=2, stride=1, padding=0)\n        (relu): ReLU(inplace)\n      )\n      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n      (conv1): Sequential(\n        (0): Conv2d(352, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): ReLU(inplace)\n      )\n      (conv2): Sequential(\n        (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): ReLU(inplace)\n      )\n      (relu): ReLU()\n    )\n    (6): UnetBlockSmall(\n      (shuf): PixelShuffle_ICNR(\n        (conv): Sequential(\n          (0): Conv2d(88, 176, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (shuf): PixelShuffle(upscale_factor=2)\n        (pad): ReplicationPad2d((1, 0, 1, 0))\n        (blur): AvgPool2d(kernel_size=2, stride=1, padding=0)\n        (relu): ReLU(inplace)\n      )\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.025, affine=True, track_running_stats=True)\n      (conv1): Sequential(\n        (0): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): ReLU(inplace)\n      )\n      (conv2): Sequential(\n        (0): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): ReLU(inplace)\n      )\n      (relu): ReLU()\n    )\n    (7): PixelShuffle_ICNR(\n      (conv): Sequential(\n        (0): Conv2d(108, 432, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (shuf): PixelShuffle(upscale_factor=2)\n      (pad): ReplicationPad2d((1, 0, 1, 0))\n      (blur): AvgPool2d(kernel_size=2, stride=1, padding=0)\n      (relu): ReLU(inplace)\n    )\n    (8): MergeLayer()\n    (9): SequentialEx(\n      (layers): ModuleList(\n        (0): Sequential(\n          (0): Conv2d(111, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n        )\n        (1): Sequential(\n          (0): Conv2d(55, 111, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace)\n        )\n        (2): MergeLayer()\n      )\n    )\n    (10): Hcolumns(\n      (factorization): ModuleList(\n        (0): Sequential(\n          (0): Conv2d(192, 55, kernel_size=(1, 1), stride=(1, 1))\n          (1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (2): Conv2d(55, 111, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): Sequential(\n          (0): Conv2d(88, 55, kernel_size=(1, 1), stride=(1, 1))\n          (1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (2): Conv2d(55, 111, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): Sequential(\n          (0): Conv2d(108, 55, kernel_size=(1, 1), stride=(1, 1))\n          (1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (2): Conv2d(55, 111, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n    )\n    (11): Sequential(\n      (0): Conv2d(444, 2, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n)\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='2', style='width:300px; height:20px; vertical-align: middle;'></progress>\n      0.00% [0/2 00:00<00:00]\n    </div>\n    \n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>dice</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>\n\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='350' class='' max='500', style='width:300px; height:20px; vertical-align: middle;'></progress>\n      70.00% [350/500 03:40<01:34 0.0152]\n    </div>\n    "},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls -lh","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# test fastai"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.vision import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = untar_data(URLs.MNIST_SAMPLE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = ImageDataBunch.from_folder(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = cnn_learner(data, models.resnet50, metrics=accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Geting the data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Overview\nThe primary goal of this competition is identification and segmentation of chest radiographic images with pneumothorax. In this kernel a U-net based approach is used, which provides end-to-end framework for image segmentation. In prior image segmentation competitions ([Airbus Ship Detection Challenge](https://www.kaggle.com/c/airbus-ship-detection/discussion) and [TGS Salt Identification Challenge](https://www.kaggle.com/c/tgs-salt-identification-challenge)), U-net based model architecture has demonstrated supperior performence, and top solutions are based on it. The current competition is similar to TGS Salt Identification Challenge in terms of identifying the correct mask based on visual inspection of images. Therefore, I have tried a technique that was extremely effective in Salt competition - [Hypercolumns](https://towardsdatascience.com/review-hypercolumn-instance-segmentation-367180495979).\n\nAs a starting point [this public kernel](https://www.kaggle.com/mnpinto/pneumothorax-fastai-u-net) is used, and the following things are added (see text below for more details):\n* Hypercolumns\n* Gradient accumulation\n* TTA based on horizontal flip\n* Noise removal (if the predicted mask contains too few pixels, it is assumed to be empty)\n* Image equilibration"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport sys\nsys.path.insert(0, '../input/siim-acr-pneumothorax-segmentation')\n\nimport fastai\nfrom fastai.vision import *\nfrom mask_functions import *\nfrom fastai.callbacks import SaveModelCallback\nimport gc\nfrom sklearn.model_selection import KFold\nfrom PIL import Image\n\nfastai.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import mask_functions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_functions??","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nprint('\\n'.join(sys.path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from mask_functions import *","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false},"cell_type":"markdown","source":"The original images, provided in this competition, have 1024x1024 resolution. To prevent additional overhead on image loading, the datasets composed of 128x128 and 256x256 scaled down images are prepared separately and used as an input. Check [this keknel](https://www.kaggle.com/iafoss/data-repack-and-image-statistics) for more details on image rescaling and mask generation. Also In that kernel I apply image normalization based on histograms (exposure.equalize_adapthist) that provides some improvement of image appearance as well as a small boost of the model performance. The corresponding pixel statistics are computed in the kernel."},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"sz = 256\nbs = 16\nn_acc = 64//bs #gradinet accumulation steps\nnfolds = 4\nSEED = 2019\n\n#eliminate all predictions with a few (noise_th) pixesls\nnoise_th = 75.0*(sz/128.0)**2 #threshold for the number of predicted pixels\nbest_thr0 = 0.2 #preliminary value of the threshold for metric calculation\n\nif sz == 256:\n    stats = ([0.540,0.540,0.540],[0.264,0.264,0.264])\n    TRAIN = '../input/siimacr-pneumothorax-segmentation-data-256/train'\n    TEST = '../input/siimacr-pneumothorax-segmentation-data-256/test'\n    MASKS = '../input/siimacr-pneumothorax-segmentation-data-256/masks'\nelif sz == 128:\n    stats = ([0.615,0.615,0.615],[0.291,0.291,0.291])\n    TRAIN = '../input/siimacr-pneumothorax-segmentation-data-128/train'\n    TEST = '../input/siimacr-pneumothorax-segmentation-data-128/test'\n    MASKS = '../input/siimacr-pneumothorax-segmentation-data-128/masks'\n\n# copy pretrained weights for resnet34 to the folder fastai will search by default\nPath('/tmp/.cache/torch/checkpoints/').mkdir(exist_ok=True, parents=True)\n!cp '../input/resnet34/resnet34.pth' '/tmp/.cache/torch/checkpoints/resnet34-333f7ec4.pth'\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    #tf.set_random_seed(seed)\nseed_everything(SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model"},{"metadata":{},"cell_type":"markdown","source":"The model used in this kernel is based on U-net like architecture with ResNet34 encoder. To boost the model performance, Hypercolumns are incorporated into DynamicUnet fast.ai class (see code below). The idea of Hypercolumns is schematically illustrated in the following figure. ![](https://i.ibb.co/3y7f8rj/Hypercolumns1.png)\nEach upscaling block is connected to the output layer through linear resize to the original image size. So the final image is produced based on concatenation of U-net output with resized outputs of intermediate layers. These skip-connections provide a shortcut for gradient flow improving model performance and convergence speed. Since intermediate layers have many channels, their upscaling and use as an input for the final layer would introduce a significant overhead in terms the computational time and memory. Therefore, 3x3 convolutions are applied (factorization) before the resize to reduce the number of channels.\nFurther details on Hypercolumns can be found [here](http://home.bharathh.info/pubs/pdfs/BharathCVPR2015.pdf) and [here](https://towardsdatascience.com/review-hypercolumn-instance-segmentation-367180495979). Below the fast.ai code modified to incorporate Hypercolumns."},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.vision.learner import create_head, cnn_config, num_features_model, create_head\nfrom fastai.callbacks.hooks import model_sizes, hook_outputs, dummy_eval, Hook, _hook_inner\nfrom fastai.vision.models.unet import _get_sfs_idxs, UnetBlock\n\nclass Hcolumns(nn.Module):\n    def __init__(self, hooks:Collection[Hook], nc:Collection[int]=None):\n        super(Hcolumns,self).__init__()\n        self.hooks = hooks\n        self.n = len(self.hooks)\n        self.factorization = None \n        if nc is not None:\n            self.factorization = nn.ModuleList()\n            for i in range(self.n):\n                self.factorization.append(nn.Sequential(\n                    conv2d(nc[i],nc[-1],3,padding=1,bias=True),\n                    conv2d(nc[-1],nc[-1],3,padding=1,bias=True)))\n                #self.factorization.append(conv2d(nc[i],nc[-1],3,padding=1,bias=True))\n        \n    def forward(self, x:Tensor):\n        n = len(self.hooks)\n        out = [F.interpolate(self.hooks[i].stored if self.factorization is None\n            else self.factorization[i](self.hooks[i].stored), scale_factor=2**(self.n-i),\n            mode='bilinear',align_corners=False) for i in range(self.n)] + [x]\n        return torch.cat(out, dim=1)\n\nclass DynamicUnet_Hcolumns(SequentialEx):\n    \"Create a U-Net from a given architecture.\"\n    def __init__(self, encoder:nn.Module, n_classes:int, blur:bool=False, blur_final=True, \n                 self_attention:bool=False,\n                 y_range:Optional[Tuple[float,float]]=None,\n                 last_cross:bool=True, bottle:bool=False, **kwargs):\n        imsize = (256,256)\n        sfs_szs = model_sizes(encoder, size=imsize)\n        sfs_idxs = list(reversed(_get_sfs_idxs(sfs_szs)))\n        self.sfs = hook_outputs([encoder[i] for i in sfs_idxs])\n        x = dummy_eval(encoder, imsize).detach()\n\n        ni = sfs_szs[-1][1]\n        middle_conv = nn.Sequential(conv_layer(ni, ni*2, **kwargs),\n                                    conv_layer(ni*2, ni, **kwargs)).eval()\n        x = middle_conv(x)\n        layers = [encoder, batchnorm_2d(ni), nn.ReLU(), middle_conv]\n\n        self.hc_hooks = [Hook(layers[-1], _hook_inner, detach=False)]\n        hc_c = [x.shape[1]]\n        \n        for i,idx in enumerate(sfs_idxs):\n            not_final = i!=len(sfs_idxs)-1\n            up_in_c, x_in_c = int(x.shape[1]), int(sfs_szs[idx][1])\n            do_blur = blur and (not_final or blur_final)\n            sa = self_attention and (i==len(sfs_idxs)-3)\n            unet_block = UnetBlock(up_in_c, x_in_c, self.sfs[i], final_div=not_final, \n                blur=blur, self_attention=sa, **kwargs).eval()\n            layers.append(unet_block)\n            x = unet_block(x)\n            self.hc_hooks.append(Hook(layers[-1], _hook_inner, detach=False))\n            hc_c.append(x.shape[1])\n\n        ni = x.shape[1]\n        if imsize != sfs_szs[0][-2:]: layers.append(PixelShuffle_ICNR(ni, **kwargs))\n        if last_cross:\n            layers.append(MergeLayer(dense=True))\n            ni += in_channels(encoder)\n            layers.append(res_block(ni, bottle=bottle, **kwargs))\n        hc_c.append(ni)\n        layers.append(Hcolumns(self.hc_hooks, hc_c))\n        layers += [conv_layer(ni*len(hc_c), n_classes, ks=1, use_activ=False, **kwargs)]\n        if y_range is not None: layers.append(SigmoidRange(*y_range))\n        super().__init__(*layers)\n\n    def __del__(self):\n        if hasattr(self, \"sfs\"): self.sfs.remove()\n            \ndef unet_learner(data:DataBunch, arch:Callable, pretrained:bool=True, blur_final:bool=True,\n        norm_type:Optional[NormType]=NormType, split_on:Optional[SplitFuncOrIdxList]=None, \n        blur:bool=False, self_attention:bool=False, y_range:Optional[Tuple[float,float]]=None, \n        last_cross:bool=True, bottle:bool=False, cut:Union[int,Callable]=None, \n        hypercolumns=True, **learn_kwargs:Any)->Learner:\n    \"Build Unet learner from `data` and `arch`.\"\n    meta = cnn_config(arch)\n    body = create_body(arch, pretrained, cut)\n    M = DynamicUnet_Hcolumns if hypercolumns else DynamicUnet\n    model = to_device(M(body, n_classes=data.c, blur=blur, blur_final=blur_final,\n        self_attention=self_attention, y_range=y_range, norm_type=norm_type, \n        last_cross=last_cross, bottle=bottle), data.device)\n    learn = Learner(data, model, **learn_kwargs)\n    learn.split(ifnone(split_on, meta['split']))\n    if pretrained: learn.freeze()\n    apply_init(model[2], nn.init.kaiming_normal_)\n    return learn","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accumulation of gradients to overcome the problem of too small batches. The code is mostly based on [this post](https://forums.fast.ai/t/accumulating-gradients/33219/25) with slight adjustment to work with mean reduction."},{"metadata":{"trusted":true},"cell_type":"code","source":"class AccumulateOptimWrapper(OptimWrapper):\n    def step(self):           pass\n    def zero_grad(self):      pass\n    def real_step(self):      super().step()\n    def real_zero_grad(self): super().zero_grad()\n        \ndef acc_create_opt(self, lr:Floats, wd:Floats=0.):\n        \"Create optimizer with `lr` learning rate and `wd` weight decay.\"\n        self.opt = AccumulateOptimWrapper.create(self.opt_func, lr, self.layer_groups,\n                                         wd=wd, true_wd=self.true_wd, bn_wd=self.bn_wd)\nLearner.create_opt = acc_create_opt   \n\n@dataclass\nclass AccumulateStep(LearnerCallback):\n    \"\"\"\n    Does accumlated step every nth step by accumulating gradients\n    \"\"\"\n    def __init__(self, learn:Learner, n_step:int = 1):\n        super().__init__(learn)\n        self.n_step = n_step\n\n    def on_epoch_begin(self, **kwargs):\n        \"init samples and batches, change optimizer\"\n        self.acc_batches = 0\n        \n    def on_batch_begin(self, last_input, last_target, **kwargs):\n        \"accumulate samples and batches\"\n        self.acc_batches += 1\n        \n    def on_backward_end(self, **kwargs):\n        \"step if number of desired batches accumulated, reset samples\"\n        if (self.acc_batches % self.n_step) == self.n_step - 1:\n            for p in (self.learn.model.parameters()):\n                if p.requires_grad: p.grad.div_(self.acc_batches)\n    \n            self.learn.opt.real_step()\n            self.learn.opt.real_zero_grad()\n            self.acc_batches = 0\n    \n    def on_epoch_end(self, **kwargs):\n        \"step the rest of the accumulated grads\"\n        if self.acc_batches > 0:\n            for p in (self.learn.model.parameters()):\n                if p.requires_grad: p.grad.div_(self.acc_batches)\n            self.learn.opt.real_step()\n            self.learn.opt.real_zero_grad()\n            self.acc_batches = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def set_BN_momentum(model,momentum=0.1*bs/64):\n    for i, (name, layer) in enumerate(model.named_modules()):\n        if isinstance(layer, nn.BatchNorm2d) or isinstance(layer, nn.BatchNorm1d):\n            layer.momentum = momentum","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A slight modification of the default dice metric to make it comparable with the competition metric: dice is computed for each image independently, and dice of empty image with zero prediction is 1. Also I use noise removal and similar threshold as in my prediction pipline."},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice(input:Tensor, targs:Tensor, iou:bool=False, eps:float=1e-8)->Rank0Tensor:\n    n = targs.shape[0]\n    input = torch.softmax(input, dim=1)[:,1,...].view(n,-1)\n    input = (input > best_thr0).long()\n    input[input.sum(-1) < noise_th,...] = 0.0 \n    #input = input.argmax(dim=1).view(n,-1)\n    targs = targs.view(n,-1)\n    intersect = (input * targs).sum(-1).float()\n    union = (input+targs).sum(-1).float()\n    if not iou: return ((2.0*intersect + eps) / (union+eps)).mean()\n    else: return ((intersect + eps) / (union - intersect + eps)).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dice for threshold selection\ndef dice_overall(preds, targs):\n    n = preds.shape[0]\n    preds = preds.view(n, -1)\n    targs = targs.view(n, -1)\n    intersect = (preds * targs).sum(-1).float()\n    union = (preds+targs).sum(-1).float()\n    u0 = union==0\n    intersect[u0] = 1\n    union[u0] = 2\n    return (2. * intersect / union)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following function generates predictions with using flip TTA (average the result for the original image and a flipped one)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction with flip TTA\ndef pred_with_flip(learn:fastai.basic_train.Learner,\n                   ds_type:fastai.basic_data.DatasetType=DatasetType.Valid):\n    #get prediction\n    preds, ys = learn.get_preds(ds_type)\n    preds = preds[:,1,...]\n    #add fiip to dataset and get prediction\n    learn.data.dl(ds_type).dl.dataset.tfms.append(flip_lr())\n    preds_lr, ys = learn.get_preds(ds_type)\n    del learn.data.dl(ds_type).dl.dataset.tfms[-1]\n    preds_lr = preds_lr[:,1,...]\n    ys = ys.squeeze()\n    preds = 0.5*(preds + torch.flip(preds_lr,[-1]))\n    del preds_lr\n    gc.collect()\n    torch.cuda.empty_cache()\n    return preds, ys","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting div=True in open_mask\nclass SegmentationLabelList(SegmentationLabelList):\n    def open(self, fn): return open_mask(fn, div=True)\n    \nclass SegmentationItemList(SegmentationItemList):\n    _label_cls = SegmentationLabelList\n\n# Setting transformations on masks to False on test set\ndef transform(self, tfms:Optional[Tuple[TfmList,TfmList]]=(None,None), **kwargs):\n    if not tfms: tfms=(None,None)\n    assert is_listy(tfms) and len(tfms) == 2\n    self.train.transform(tfms[0], **kwargs)\n    self.valid.transform(tfms[1], **kwargs)\n    kwargs['tfm_y'] = False # Test data has no labels\n    if self.test: self.test.transform(tfms[1], **kwargs)\n    return self\nfastai.data_block.ItemLists.transform = transform","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data(fold):\n    kf = KFold(n_splits=nfolds, shuffle=True, random_state=SEED)\n    valid_idx = list(kf.split(list(range(len(Path(TRAIN).ls())))))[fold][1]\n    # Create databunch\n    data = (SegmentationItemList.from_folder(TRAIN)\n            .split_by_idx(valid_idx)\n            .label_from_func(lambda x : str(x).replace('train', 'masks'), classes=[0,1])\n            .add_test(Path(TEST).ls(), label=None)\n            .transform(get_transforms(), size=sz, tfm_y=True)\n            .databunch(path=Path('.'), bs=bs)\n            .normalize(stats))\n    return data\n\n# Display some images with masks\n#get_data(0).show_batch()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}