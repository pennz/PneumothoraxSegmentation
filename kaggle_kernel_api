# My conclusion about kaggle kernels API

Using this API, you need to push and pull, somewhat inefficient. But your code history can be maintained locally using CVS.
For notebook type, you should edit .ipynb file (there are commands to convert .py to .ipynb). For script type kernel, python script. Both types run only one file specified by you. 
If your scripts contains multiple files (different modules or something), it is not easy to do. As you can only add your
"utility" scripts as separate kernels, and refer to that kernel if you want to use.

But if you need to do submission **automation**, the API will help. If you need to do interactive things (like debugging), you need to use the webpage.

# Set up kaggle command line tool
[official github page API](https://github.com/Kaggle/kaggle-api#kernels)

For Linux or MacOS environments, you can use the following commands. For detail, check this: [detail reference to set up kaggle command line tools](https://www.kaggle.com/docs/api#interacting-with-kernels)

For the token for Kaggle's public API in the third command, reference [this](https://www.kaggle.com/docs/api#authentication).

```sh
pip install kaggle 
mkdir $HOME/.kaggle 
echo '{"username":"k1gaggle","key":"b1946ac92492d2347c6235b4d2611184"}' > $HOME/.kaggle/kaggle.json
chmod 600 $HOME/.kaggle/kaggle.json
```

# command line examples
```sh
$ kaggle kernels list # to show all kernels

$ kaggle kernels list -m  # show mine

$ kaggle kernels list -m --competition siim-acr-pneumothorax-segmentation  # show my kernel for the competition
ref                               title                    author  lastRunTime          totalVotes  
--------------------------------  -----------------------  ------  -------------------  ----------  
k1gaggle/learn-pytorch-mask-rcnn  learn pytorch mask-rcnn  V Zhou  2019-07-04 05:20:10           0  

$ mkdir kaggle_api_test && kaggle kernels pull k1gaggle/learn-pytorch-mask-rcnn -p kaggle_api_test
Source code downloaded to kaggle_api_test/learn-pytorch-mask-rcnn.ipynb

# retrive kernel's output
$ kaggle kernels output k1gaggle/learn-pytorch-mask-rcnn -p kaggle_api_test
Output file downloaded to kaggle_api_test/kernel.py
Output file downloaded to kaggle_api_test/submission.csv
Output file downloaded to kaggle_api_test/run_state_KernelRunningState.TRAINING_DONE.pkl
...
Kernel log downloaded to kaggle_api_test/learn-pytorch-mask-rcnn.log 

# Get the status of the latest kernel run
$ kaggle kernels status k1gaggle/learn-pytorch-mask-rcnn 
k1gaggle/learn-pytorch-mask-rcnn has status "complete"
```

# Using API to pull code and submit new code
```sh
# download your online kernel, you edit the kernel based on this online existed kernels
$ mkdir test && kaggle kernels pull k1gaggle/learn-pytorch-mask-rcnn -m  -p test

# change your metadata, reference https://github.com/Kaggle/kaggle-api/wiki/Kernel-Metadata
$ vi test/kernel-metadata.json  
$ kaggle kernels push -p test
Kernel version 1 successfully pushed.  Please check progress at https://www.kaggle.com/k1gaggle/learn-api

$ kaggle kernels status k1gaggle/learn-api
k1gaggle/learn-api has status "running"

# pull again, just to overwrite the 'id_no' in metadata, just in case
$ kaggle kernels pull k1gaggle/learn-api -m  -p test

# edit your ipynb code
$ kaggle kernels push -p test
Kernel version 2 successfully pushed.  Please check progress at https://www.kaggle.com/k1gaggle/learn-api

$ kaggle kernels status k1gaggle/learn-api
k1gaggle/learn-api has status "running"

# besides, the pushed kernels are 'committed' versions, which makes it easier to see previous versions in webpages too.
```
![commited versions](commited_versions.png)

So we can edit the code in our offline env, push it to kaggle online kernel, and then let it run and wait for its output.